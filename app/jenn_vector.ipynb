{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-cli in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (0.0.32)\n",
      "Requirement already satisfied: gitpython<4,>=3 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-cli) (3.1.43)\n",
      "Requirement already satisfied: gritql<0.2.0,>=0.1.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-cli) (0.1.5)\n",
      "Requirement already satisfied: langserve>=0.0.51 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve[all]>=0.0.51->langchain-cli) (0.3.0)\n",
      "Requirement already satisfied: tomlkit>=0.12 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-cli) (0.12.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.9.4)\n",
      "Requirement already satisfied: uvicorn<1.0,>=0.23 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-cli) (0.32.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from gitpython<4,>=3->langchain-cli) (4.0.7)\n",
      "Requirement already satisfied: httpx<1.0,>=0.23.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.27.0)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.3.18)\n",
      "Requirement already satisfied: orjson<4,>=2 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.10.11)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.9.2)\n",
      "Requirement already satisfied: fastapi<1,>=0.90.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve[all]>=0.0.51->langchain-cli) (0.115.4)\n",
      "Requirement already satisfied: sse-starlette<2.0.0,>=1.3.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langserve[all]>=0.0.51->langchain-cli) (1.8.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (4.11.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from uvicorn<1.0,>=0.23->langchain-cli) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from fastapi<1,>=0.90.1->langserve[all]>=0.0.51->langchain-cli) (0.41.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3->langchain-cli) (4.0.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (4.6.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.1.140)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (8.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from pydantic<3.0,>=2.7->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from pydantic<3.0,>=2.7->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (2.15.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from anyio->httpx<1.0,>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/dev/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Document loading, retrieval methods and text splitting\n",
    "%pip install -qU langchain langchain_community\n",
    "\n",
    "# Local vector store via Chroma\n",
    "%pip install -qU langchain_chroma\n",
    "\n",
    "# Local inference and embeddings via Ollama\n",
    "%pip install -qU langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable tracing\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Trivia Data from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='category: Category\n",
      "question: Question\n",
      "answer: Answer' metadata={'source': 'test_data/test_question_set_cleaned.csv', 'row': 0}\n",
      "page_content='category: HISTORY\n",
      "question: For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\n",
      "answer: Copernicus' metadata={'source': 'test_data/test_question_set_cleaned.csv', 'row': 1}\n",
      "page_content='category: ESPN's TOP 10 ALL-TIME ATHLETES\n",
      "question: No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves\n",
      "answer: Jim Thorpe' metadata={'source': 'test_data/test_question_set_cleaned.csv', 'row': 2}\n"
     ]
    }
   ],
   "source": [
    "# Use the LangChain CSV loader to load the trivia dataset from the CSV\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"test_data/test_question_set_cleaned.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "        \"fieldnames\": [\"category\", \"question\", \"answer\"],\n",
    "    },)\n",
    "data = loader.load()\n",
    "\n",
    "for record in data[:3]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Vector Store with nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "DEBUG:chromadb.config:Starting component System\n",
      "Starting component System\n",
      "DEBUG:chromadb.config:Starting component Posthog\n",
      "Starting component Posthog\n",
      "DEBUG:chromadb.config:Starting component OpenTelemetryClient\n",
      "Starting component OpenTelemetryClient\n",
      "DEBUG:chromadb.config:Starting component SqliteDB\n",
      "Starting component SqliteDB\n",
      "DEBUG:chromadb.config:Starting component SimpleQuotaEnforcer\n",
      "Starting component SimpleQuotaEnforcer\n",
      "DEBUG:chromadb.config:Starting component SimpleRateLimitEnforcer\n",
      "Starting component SimpleRateLimitEnforcer\n",
      "DEBUG:chromadb.config:Starting component LocalSegmentManager\n",
      "Starting component LocalSegmentManager\n",
      "DEBUG:chromadb.config:Starting component LocalExecutor\n",
      "Starting component LocalExecutor\n",
      "DEBUG:chromadb.config:Starting component SegmentAPI\n",
      "Starting component SegmentAPI\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11fbb4f70>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11fbb4f70>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): us.i.posthog.com:443\n",
      "Starting new HTTPS connection (1): us.i.posthog.com:443\n",
      "DEBUG:urllib3.connectionpool:https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n",
      "https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:02:48 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:02:48 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:chromadb.config:Starting component LocalHnswSegment\n",
      "Starting component LocalHnswSegment\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=data, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/opt/anaconda3/envs/dev/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "# Add phi3:3.8b LLM model\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"phi3:3.8b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11fbb7910>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11fbb7910>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dev/lib/python3.10/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 605\n",
      "https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 605\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=626c1ab2-dced-4597-975f-4b2eea7db2ac,id=626c1ab2-dced-4597-975f-4b2eea7db2ac\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=626c1ab2-dced-4597-975f-4b2eea7db2ac,id=626c1ab2-dced-4597-975f-4b2eea7db2ac\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:02:50 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:02:50 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "The capital of France is Paris. It'dis a major city and a global center for art, fashion, gastronomy, and culture. Its twelve administrative \"arrondissements\" are each uniquely characterized by their own distinct communities, monuments, and landmarks that contribute to the allure and charm it holds as one of Europe’s most visited cities.\n"
     ]
    }
   ],
   "source": [
    "# Test LLM model is working\n",
    "response_message = model.invoke(\"What is the capital of France?\")\n",
    "\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:02:51 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:02:51 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n",
      "https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:02:52 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:02:52 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=626c1ab2-dced-4597-975f-4b2eea7db2ac,id=626c1ab2-dced-4597-975f-4b2eea7db2ac\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=626c1ab2-dced-4597-975f-4b2eea7db2ac,id=626c1ab2-dced-4597-975f-4b2eea7db2ac\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=62bb0308-ce82-41e2-b97b-eb5973914ae7; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=c73cf3d8-56be-46d5-9bd4-1750cb4eb0db; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=ef984535-5e71-41a8-8f70-c00f8bd40532; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=56af9f34-f7f3-4dcb-9841-8af1be485caa; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=85f2467d-e584-4f6b-96c4-4c317764ca0a\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=62bb0308-ce82-41e2-b97b-eb5973914ae7; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=c73cf3d8-56be-46d5-9bd4-1750cb4eb0db; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=ef984535-5e71-41a8-8f70-c00f8bd40532; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=56af9f34-f7f3-4dcb-9841-8af1be485caa; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=85f2467d-e584-4f6b-96c4-4c317764ca0a\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=fea394f2-0347-43f9-a893-bc65372185b1; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=62bb0308-ce82-41e2-b97b-eb5973914ae7; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=85f2467d-e584-4f6b-96c4-4c317764ca0a\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=fea394f2-0347-43f9-a893-bc65372185b1; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=62bb0308-ce82-41e2-b97b-eb5973914ae7; trace=62bb0308-ce82-41e2-b97b-eb5973914ae7,id=85f2467d-e584-4f6b-96c4-4c317764ca0a\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: api.smith.langchain.com\n",
      "Resetting dropped connection: api.smith.langchain.com\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=28819cd7-8a8b-4295-85ee-fb1ad707e5e2; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=b680abd7-8892-4f17-8032-648e47897dd9; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=ce30b9de-351d-4d28-8185-307fd9fe8015; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=3ff8e84d-00f3-4f5c-a2c5-23b95d048de9; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=c3e043f1-ebfb-4dc8-acbe-2ba23322bdb4; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=7a8b8600-f778-49d3-87b6-137eab8e5e92\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=28819cd7-8a8b-4295-85ee-fb1ad707e5e2; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=b680abd7-8892-4f17-8032-648e47897dd9; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=ce30b9de-351d-4d28-8185-307fd9fe8015; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=3ff8e84d-00f3-4f5c-a2c5-23b95d048de9; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=c3e043f1-ebfb-4dc8-acbe-2ba23322bdb4; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=7a8b8600-f778-49d3-87b6-137eab8e5e92\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 401 26\n",
      "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=0b665fed-ffc0-4ef0-bd8d-cca419ecc498; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=28819cd7-8a8b-4295-85ee-fb1ad707e5e2; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=7a8b8600-f778-49d3-87b6-137eab8e5e92\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=0b665fed-ffc0-4ef0-bd8d-cca419ecc498; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=28819cd7-8a8b-4295-85ee-fb1ad707e5e2; trace=28819cd7-8a8b-4295-85ee-fb1ad707e5e2,id=7a8b8600-f778-49d3-87b6-137eab8e5e92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Main themes in the retrieved docs include various cultural, professional and scientific aspects. Here are some summarized main points according to different categories mentioned in the documents:\\n\\n- Category EVERYBODY TALKS ABOUT IT... - This category focuses on common topics or issues that people frequently discuss. In this case, it is about a widely recognized tool for measuring and understanding sun exposure called \"the UV index\". The document explains its importance since June 28, 1994 when the National Weather Service started issuing it to rate solar radiation intensity in order to safeguard public health.\\n  \\n- Category VARIETY PACK - In this category are mentioned two distinct concepts: a slang term used by musicians and others for job opportunities or engagements, referred as \"a gig\", and also the name of an object (pronged spear) that is traditionally employed in fishing activities.\\n  \\n- Category CORN-UCOPIA - This category provides details about a specific type of liquor known as bourbon which originated from distilling corn mash with certain percentage limits, specifically between 51% and 79%. Bourbon has since become an iconic representation for American spirit production.\\n\\nIn summary, these documents cover the broad spectrums in social life such as music industry norm (gig), traditional fishing methods(pronged spear), scientific advancements in weather prediction (UV index) and even touch on a cultural element of liquor making specifically bourbon that relies heavily on corn.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the retrieval chain is working\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What is the most popular category?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041c1570>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041c1570>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:03:00 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 21 Nov 2024 21:03:00 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:03:01 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Thu, 21 Nov 2024 21:03:01 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Task decomposition is a critical aspect in various fields, including artificial intelligence and human task management. Here are some general strategies for decomposing tasks effectively:\\n\\n1. Hierarchical decomposition - This method involves breaking down complex tasks into simpler subtasks recursively until each piece becomes manageable or trivial enough to perform independently. In this approach, a top-down strategy is often employed where the system starts with an overview of the task and progressively refines it by identifying smaller units within that scope.\\n\\n2. Bottom-up decomposition - This method begins at the most granular level possible in pursuit to identify subtasks before moving on to higher levels, effectively starting from small components working their way up through a hierarchy until reaching more significant tasks or goals. It can sometimes be useful when there is clear evidence of how individual pieces contribute towards completing an overall task without prior knowledge about the structure and dependencies between these pieces.\\n\\n3. Divide et impera (divide and conquer) - In this strategy, complex problems are decomposed by dividing them into smaller subproblems that can be solved independently or in parallel; subsequently integrating their solutions to attain an overall solution for larger issues at hand. The process involves identifying divisible sections of a task where each independent part is simpler than the original problem but still challenging when faced alone, ensuring efficient and scalable decomposition processes particularly useful with computer algorithms.\\n\\n4. Formal methods - In this approach to decomposing tasks, formal logic systems or mathematical frameworks are employed in order to describe complex problems accurately as well as their potential subtasks for effective management and solution identification within a defined environment such as hardware architecture optimization scenarios where concurrency is involved (e.g., multi-threaded processes).\\n\\n5. Use of domain knowledge - Specialized expertise about the relevant field can facilitate more efficient task decomposition when this information is available, helping in identifying natural subtasks along with their respective dependencies or prerequisites necessary for successful completion based on prior experience and understanding concerning how such tasks are usually approached within that specific discipline.\\n\\n6. User input - Sometimes a user's perspective may be incorporated into the task decomposition process where an individual is asked to choose among pre-defined categories of workload subtasks (e.g., asking users what aspects they find most challenging or time consuming in executing tasks), which can help prioritize efforts towards completing more difficult components first, thus improving overall efficiency and reducing completion times by working with user input rather than generic approaches that may not be tailored to individual preferences/dynamics.\\n\\nThese are general methodologies for task decomposition; there could also exist hybridized or multi-faceted strategies in practice based on specific requirements, the nature of tasks themselves and their environments as well as available tools, resources & capabilities at hand while devising a plan to tackle complex activities efficiently.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic RAG prompt - needs to be updated to use our RAG model and workflow / chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are a trivial chatbot. You will be asked questions and you will provide answers based on the context provided.\n",
    "You will give the user a set of categories and ask them to choose one. You will then provide a question from that category.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
